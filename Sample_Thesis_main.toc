\contentsline {chapter}{\numberline {1}Introduction}{1}{}%
\contentsline {section}{\numberline {1.1}Problem Statement and Motivation}{2}{}%
\contentsline {section}{\numberline {1.2}Research Objectives and Contributions}{2}{}%
\contentsline {section}{\numberline {1.3}Methodology and Approach}{4}{}%
\contentsline {section}{\numberline {1.4}Dissertation Organization}{5}{}%
\contentsline {section}{\numberline {1.5}Expected Impact and Significance}{5}{}%
\contentsline {chapter}{\numberline {2}Background and Definitions}{7}{}%
\contentsline {section}{\numberline {2.1}Out of Distribution Detection}{7}{}%
\contentsline {section}{\numberline {2.2}Anomaly Detection}{8}{}%
\contentsline {subsection}{\numberline {2.2.1}Definiton and Scope}{9}{}%
\contentsline {subsection}{\numberline {2.2.2}Training Assumptions}{9}{}%
\contentsline {subsection}{\numberline {2.2.3}Evaluation Settings}{9}{}%
\contentsline {section}{\numberline {2.3}Information Theory}{10}{}%
\contentsline {subsection}{\numberline {2.3.1}Entropy and Mutual Information}{11}{}%
\contentsline {section}{\numberline {2.4}Information Bottleneck and Minimal Sufficient Statistic}{11}{}%
\contentsline {subsection}{\numberline {2.4.1}Minimal Sufficient Statistic}{12}{}%
\contentsline {subsection}{\numberline {2.4.2}Information Bottleneck}{12}{}%
\contentsline {section}{\numberline {2.5}Dataset Domain}{13}{}%
\contentsline {subsection}{\numberline {2.5.1}Domain Features and Domain Feature Collapse}{15}{}%
\contentsline {section}{\numberline {2.6}Unlabeled OOD Detection}{16}{}%
\contentsline {section}{\numberline {2.7}Large Language Models}{17}{}%
\contentsline {chapter}{\numberline {3}Literature Review}{20}{}%
\contentsline {section}{\numberline {3.1}Information Theory in Machine Learning}{20}{}%
\contentsline {section}{\numberline {3.2}Representation Learning}{21}{}%
\contentsline {subsection}{\numberline {3.2.1}Unsupervised Representation Learning}{22}{}%
\contentsline {subsection}{\numberline {3.2.2}Self-Supervised Learning}{22}{}%
\contentsline {section}{\numberline {3.3}Out of Distribution Detection}{23}{}%
\contentsline {subsection}{\numberline {3.3.1}Classical and Training-Agnostic Approaches}{23}{}%
\contentsline {subsection}{\numberline {3.3.2}Self-Supervised and Unsupervised OOD Detection}{24}{}%
\contentsline {subsection}{\numberline {3.3.3}Benchmarking and Evaluation}{24}{}%
\contentsline {subsection}{\numberline {3.3.4}Single-Domain OOD Detection}{25}{}%
\contentsline {subsection}{\numberline {3.3.5}Domain Adaptation and Transfer Learning}{26}{}%
\contentsline {subsection}{\numberline {3.3.6}Multi-Stage and Ensemble Approaches}{27}{}%
\contentsline {section}{\numberline {3.4}Hallucination Detection}{27}{}%
\contentsline {subsection}{\numberline {3.4.1}Taxonomy of Hallucination Detection Approaches}{28}{}%
\contentsline {subsection}{\numberline {3.4.2}Information-Theoretic Perspectives}{28}{}%
\contentsline {subsection}{\numberline {3.4.3}Evaluation and Benchmarks}{29}{}%
\contentsline {section}{\numberline {3.5}Model Architectures}{29}{}%
\contentsline {subsection}{\numberline {3.5.1}Convolutional Neural Networks}{29}{}%
\contentsline {subsection}{\numberline {3.5.2}Transformers}{29}{}%
\contentsline {subsection}{\numberline {3.5.3}Foundation Models}{30}{}%
\contentsline {chapter}{\numberline {4}Label Blindness in Unlabeled OOD Detection}{31}{}%
\contentsline {section}{\numberline {4.1}Introduction}{31}{}%
\contentsline {section}{\numberline {4.2}Preliminaries}{34}{}%
\contentsline {subsection}{\numberline {4.2.1}Labeled and Unlabeled Out-of-Distribution Detection}{34}{}%
\contentsline {subsection}{\numberline {4.2.2}Self-Supervised and Unsupervised Learning}{34}{}%
\contentsline {section}{\numberline {4.3}Guaranteed OOD Detection Failure}{36}{}%
\contentsline {subsection}{\numberline {4.3.1}Label Blindness Theorem (Strict Label Blindness)}{36}{}%
\contentsline {subsection}{\numberline {4.3.2}Implications of Strict Label Blindness in Real World Situations}{38}{}%
\contentsline {subsection}{\numberline {4.3.3}Theoretical Implications}{38}{}%
\contentsline {section}{\numberline {4.4}Benchmarking for Label Blindness Failure}{39}{}%
\contentsline {subsection}{\numberline {4.4.1}Bootstrapping and the Adjacent OOD Benchmark}{39}{}%
\contentsline {subsection}{\numberline {4.4.2}Why Adjacent OOD is Safety-Critical to Almost All Real World Systems}{39}{}%
\contentsline {subsection}{\numberline {4.4.3}Comparing Adjacent, Near, and Far OOD Benchmarks}{40}{}%
\contentsline {subsection}{\numberline {4.4.4}Implications for OOD from Unlabeled Data}{40}{}%
\contentsline {section}{\numberline {4.5}Experimental Results}{41}{}%
\contentsline {subsection}{\numberline {4.5.1}Experimental Setup}{41}{}%
\contentsline {paragraph}{Supervised Baseline.}{41}{}%
\contentsline {paragraph}{Self-supervised Baselines.}{41}{}%
\contentsline {paragraph}{Unsupervised Baseline.}{42}{}%
\contentsline {paragraph}{Zero-shot Baseline.}{42}{}%
\contentsline {subsection}{\numberline {4.5.2}Adjacent OOD Datasets}{42}{}%
\contentsline {subsection}{\numberline {4.5.3}Experimental Results}{43}{}%
\contentsline {section}{\numberline {4.6}Discussion}{44}{}%
\contentsline {subsection}{\numberline {4.6.1}Impact of Label Blindness on Future Research}{44}{}%
\contentsline {subsection}{\numberline {4.6.2}Recommendations for Future OOD Detection Research}{45}{}%
\contentsline {section}{\numberline {4.7}Conclusion}{45}{}%
\contentsline {chapter}{\numberline {5}Domain Feature Collapse in Single-Domain OOD Detection}{47}{}%
\contentsline {section}{\numberline {5.1}Introduction}{47}{}%
\contentsline {section}{\numberline {5.2}Problem Formulation}{48}{}%
\contentsline {subsection}{\numberline {5.2.1}Single-Domain Datasets and Domain Features}{48}{}%
\contentsline {section}{\numberline {5.3}Theoretical Analysis: Domain Feature Collapse}{49}{}%
\contentsline {subsection}{\numberline {5.3.1}Implications for OOD Detection}{50}{}%
\contentsline {section}{\numberline {5.4}Domain Filtering: A Solution to Domain Feature Collapse}{51}{}%
\contentsline {subsection}{\numberline {5.4.1}Two-Stage Detector: Domain Filtering + OOD Detection}{51}{}%
\contentsline {subsection}{\numberline {5.4.2}Relationship to Near, Far, and Adjacent OOD}{52}{}%
\contentsline {section}{\numberline {5.5}Experimental Validation}{52}{}%
\contentsline {subsection}{\numberline {5.5.1}Domain Bench: Single-Domain Datasets}{52}{}%
\contentsline {subsection}{\numberline {5.5.2}Experimental Setup}{53}{}%
\contentsline {subsection}{\numberline {5.5.3}Results and Analysis}{54}{}%
\contentsline {subsection}{\numberline {5.5.4}Detailed Results by Dataset}{55}{}%
\contentsline {subsection}{\numberline {5.5.5}Case Study: Colon Dataset}{56}{}%
\contentsline {subsection}{\numberline {5.5.6}Discussion}{57}{}%
\contentsline {subsubsection}{Rock Dataset as an Outlier}{57}{}%
\contentsline {section}{\numberline {5.6}Limitations and Future Work}{58}{}%
\contentsline {subsection}{\numberline {5.6.1}Assumptions and Scope}{58}{}%
\contentsline {subsection}{\numberline {5.6.2}Generalization to Other Domains}{58}{}%
\contentsline {subsection}{\numberline {5.6.3}Alternative Solutions}{58}{}%
\contentsline {section}{\numberline {5.7}Conclusion}{59}{}%
\contentsline {chapter}{\numberline {6}Hallucinations Through Information Theory}{61}{}%
\contentsline {section}{\numberline {6.1}Introduction and Motivation}{61}{}%
\contentsline {section}{\numberline {6.2}Theoretical Framework}{62}{}%
\contentsline {subsection}{\numberline {6.2.1}Mutual Information in Language Generation}{62}{}%
\contentsline {subsection}{\numberline {6.2.2}Hallucination as Information Loss}{63}{}%
\contentsline {section}{\numberline {6.3}Proposed Research Methodology}{63}{}%
\contentsline {subsection}{\numberline {6.3.1}Mutual Information Estimation in Foundation Models}{63}{}%
\contentsline {subsubsection}{Neural Mutual Information Estimation}{63}{}%
\contentsline {subsubsection}{Variational Bounds}{64}{}%
\contentsline {subsubsection}{Kernel-Based Methods}{65}{}%
\contentsline {subsubsection}{Discrete Approximations}{65}{}%
\contentsline {subsubsection}{Contrastive Mutual Information Estimation (Proposed)}{66}{}%
\contentsline {paragraph}{Method Overview and Motivation}{66}{}%
\contentsline {paragraph}{Formal Mathematical Framework}{67}{}%
\contentsline {paragraph}{Advantages and Theoretical Justification}{68}{}%
\contentsline {paragraph}{Limitations and Challenges}{68}{}%
\contentsline {paragraph}{Implementation Considerations}{69}{}%
\contentsline {subsection}{\numberline {6.3.2}Representation Learning Analysis}{70}{}%
\contentsline {subsubsection}{Layer-wise Information Flow}{70}{}%
\contentsline {subsubsection}{Attention Mechanism Analysis}{70}{}%
\contentsline {subsubsection}{Information Bottleneck Dynamics}{70}{}%
\contentsline {section}{\numberline {6.4}Experimental Design}{70}{}%
\contentsline {subsection}{\numberline {6.4.1}Datasets and Benchmarks}{72}{}%
\contentsline {subsubsection}{Factual Question Answering Datasets:}{72}{}%
\contentsline {paragraph}{Natural Questions}{72}{}%
\contentsline {paragraph}{TriviaQA}{72}{}%
\contentsline {paragraph}{WebQuestions}{72}{}%
\contentsline {subsubsection}{Hallucination-Specific Benchmarks:}{73}{}%
\contentsline {paragraph}{HaluEval}{73}{}%
\contentsline {paragraph}{TruthfulQA}{73}{}%
\contentsline {paragraph}{FEVER}{74}{}%
\contentsline {paragraph}{HalluLens}{74}{}%
\contentsline {subsubsection}{Synthetic Validation Datasets:}{74}{}%
\contentsline {paragraph}{Gaussian Mixture Models}{75}{}%
\contentsline {paragraph}{Transformer-Based Synthetic Data}{75}{}%
\contentsline {subsection}{\numberline {6.4.2}Model Analysis}{75}{}%
\contentsline {subsubsection}{Architecture Comparison:}{75}{}%
\contentsline {paragraph}{Transformer-Based Models}{75}{}%
\contentsline {paragraph}{State-Space Models}{76}{}%
\contentsline {paragraph}{Hybrid Architectures}{76}{}%
\contentsline {subsubsection}{Scale Analysis:}{76}{}%
\contentsline {paragraph}{Parameter Count Effects}{76}{}%
\contentsline {paragraph}{Training Data Scale}{77}{}%
\contentsline {paragraph}{Context Length Analysis}{77}{}%
\contentsline {subsection}{\numberline {6.4.3}Evaluation Metrics and Protocols}{77}{}%
\contentsline {subsubsection}{Mutual Information Estimation Metrics:}{77}{}%
\contentsline {paragraph}{Synthetic Data Validation}{77}{}%
\contentsline {paragraph}{Cross-Method Consistency}{78}{}%
\contentsline {subsubsection}{Hallucination Detection Metrics:}{78}{}%
\contentsline {paragraph}{Area Under the Receiver Operating Characteristic Curve (AUROC)}{78}{}%
\contentsline {paragraph}{False Positive Rate at 95\% True Positive Rate (FPR95)}{78}{}%
\contentsline {paragraph}{Precision-Recall Analysis}{78}{}%
\contentsline {subsubsection}{Statistical Significance and Robustness:}{79}{}%
\contentsline {paragraph}{Cross-Validation and Bootstrap Sampling}{79}{}%
\contentsline {paragraph}{Multiple Random Seeds}{79}{}%
\contentsline {paragraph}{Ablation Studies}{79}{}%
\contentsline {subsubsection}{Contrastive MI Estimation Validation:}{79}{}%
\contentsline {paragraph}{Synthetic Validation Protocol}{79}{}%
\contentsline {paragraph}{Cross-Method Comparison Framework}{80}{}%
\contentsline {paragraph}{Layer Consistency Analysis}{80}{}%
\contentsline {paragraph}{Comprehensive Ablation Studies}{81}{}%
\contentsline {paragraph}{Computational Efficiency Benchmarking}{81}{}%
\contentsline {paragraph}{Hallucination Correlation Validation}{82}{}%
\contentsline {section}{\numberline {6.5}Contributions and Positioning}{82}{}%
\contentsline {subsection}{\numberline {6.5.1}Theoretical Foundations and Innovations}{82}{}%
\contentsline {subsection}{\numberline {6.5.2}Methodological Innovations and Empirical Contributions}{83}{}%
\contentsline {subsection}{\numberline {6.5.3}Bridging Theory and Practice}{85}{}%
\contentsline {subsection}{\numberline {6.5.4}Positioning Relative to Existing Work}{86}{}%
\contentsline {section}{\numberline {6.6}Challenges and Limitations}{87}{}%
\contentsline {subsection}{\numberline {6.6.1}Technical Challenges}{87}{}%
\contentsline {subsection}{\numberline {6.6.2}Theoretical Limitations}{88}{}%
\contentsline {subsection}{\numberline {6.6.3}Practical Implementation Challenges}{89}{}%
\contentsline {subsection}{\numberline {6.6.4}Validation and Evaluation Challenges}{90}{}%
\contentsline {subsection}{\numberline {6.6.5}Ethical and Societal Considerations}{91}{}%
\contentsline {section}{\numberline {6.7}Related Work}{91}{}%
\contentsline {subsection}{\numberline {6.7.1}Information Theory in Natural Language Processing}{91}{}%
\contentsline {subsubsection}{Classical Information-Theoretic Approaches}{92}{}%
\contentsline {subsubsection}{Mutual Information in Representation Learning}{92}{}%
\contentsline {subsubsection}{Information Bottleneck Theory}{92}{}%
\contentsline {subsection}{\numberline {6.7.2}Hallucination Detection and Mitigation}{93}{}%
\contentsline {subsubsection}{Confidence-Based Methods}{93}{}%
\contentsline {subsubsection}{Consistency-Based Approaches}{93}{}%
\contentsline {subsubsection}{Mechanistic Approaches}{93}{}%
\contentsline {subsection}{\numberline {6.7.3}Representation Learning in Language Models}{94}{}%
\contentsline {subsubsection}{Probing Studies}{94}{}%
\contentsline {subsubsection}{Mechanistic Interpretability}{94}{}%
\contentsline {subsubsection}{Information Flow Analysis}{94}{}%
\contentsline {subsection}{\numberline {6.7.4}Contrastive Learning in NLP}{95}{}%
\contentsline {subsubsection}{Sentence and Document Representations}{95}{}%
\contentsline {subsubsection}{Mutual Information Estimation via Contrastive Learning}{95}{}%
\contentsline {section}{\numberline {6.8}Conclusion}{95}{}%
\contentsline {chapter}{\numberline {7}Research Timeline}{97}{}%
\contentsline {section}{\numberline {7.1}Overview}{97}{}%
\contentsline {section}{\numberline {7.2}Research Timeline Gantt Chart}{97}{}%
\contentsline {subsection}{\numberline {7.2.1}Parallel Work Streams and Task Overlaps}{98}{}%
\contentsline {subsection}{\numberline {7.2.2}Key Milestones and Deliverables}{99}{}%
\contentsline {section}{\numberline {7.3}Phase 1: Foundation and Method Development (Months 1-4)}{100}{}%
\contentsline {subsection}{\numberline {7.3.1}Month 1: Theoretical Framework and Prototype Analysis}{100}{}%
\contentsline {subsection}{\numberline {7.3.2}Month 2: Contrastive MI Implementation Refinement}{100}{}%
\contentsline {subsection}{\numberline {7.3.3}Month 3: Baseline Methods and Comparison}{101}{}%
\contentsline {subsection}{\numberline {7.3.4}Month 4: Method Refinement}{101}{}%
\contentsline {section}{\numberline {7.4}Phase 2: Large-Scale Validation and Hallucination Detection (Months 5-8)}{102}{}%
\contentsline {subsection}{\numberline {7.4.1}Month 5: Foundation Model Analysis}{102}{}%
\contentsline {subsection}{\numberline {7.4.2}Month 6: Hallucination Correlation Studies}{102}{}%
\contentsline {subsection}{\numberline {7.4.3}Month 7: Detection System Development}{103}{}%
\contentsline {subsection}{\numberline {7.4.4}Month 8: Cross-Architecture Validation}{103}{}%
\contentsline {section}{\numberline {7.5}Phase 3: Applications and Deployment (Months 9-12)}{104}{}%
\contentsline {subsection}{\numberline {7.5.1}Month 9: Domain-Specific Applications}{104}{}%
\contentsline {subsection}{\numberline {7.5.2}Month 10: Intervention Strategies}{104}{}%
\contentsline {subsection}{\numberline {7.5.3}Month 11: Comprehensive Evaluation}{105}{}%
\contentsline {subsection}{\numberline {7.5.4}Month 12: Documentation and Dissemination}{105}{}%
\contentsline {section}{\numberline {7.6}Key Deliverables}{106}{}%
\contentsline {subsection}{\numberline {7.6.1}Technical Deliverables}{106}{}%
\contentsline {subsection}{\numberline {7.6.2}Research Outputs}{107}{}%
\contentsline {section}{\numberline {7.7}Risk Mitigation}{107}{}%
\contentsline {subsection}{\numberline {7.7.1}Technical Risks}{107}{}%
\contentsline {subsection}{\numberline {7.7.2}Timeline Risks}{108}{}%
\contentsline {section}{\numberline {7.8}Success Metrics}{109}{}%
\contentsline {subsection}{\numberline {7.8.1}Quantitative Metrics}{109}{}%
\contentsline {subsection}{\numberline {7.8.2}Qualitative Metrics}{109}{}%
\contentsline {chapter}{\numberline {8}Conclusion}{111}{}%
\contentsline {section}{\numberline {8.1}Summary of Proposed Contributions}{111}{}%
\contentsline {subsection}{\numberline {8.1.1}Theoretical Foundations}{111}{}%
\contentsline {subsection}{\numberline {8.1.2}Methodological Innovations}{112}{}%
\contentsline {subsection}{\numberline {8.1.3}Practical Applications and Impact}{113}{}%
\contentsline {section}{\numberline {8.2}Broader Implications and Future Directions}{113}{}%
\contentsline {subsection}{\numberline {8.2.1}AI Safety and Reliability}{113}{}%
\contentsline {subsection}{\numberline {8.2.2}Information Theory in Machine Learning}{114}{}%
\contentsline {subsection}{\numberline {8.2.3}Evaluation and Benchmarking}{114}{}%
\contentsline {section}{\numberline {8.3}Research Timeline and Feasibility}{114}{}%
\contentsline {section}{\numberline {8.4}Expected Outcomes and Success Metrics}{115}{}%
\contentsline {section}{\numberline {8.5}Concluding Remarks}{115}{}%
\contentsline {chapter}{Appendices}{129}{}%
\contentsline {chapter}{\numberline {A}Theoretical Proofs for Label Blindness}{130}{}%
\contentsline {section}{\numberline {A.1}Properties of Mutual Information and Entropy}{130}{}%
\contentsline {section}{\numberline {A.2}Supporting Theorems and Proofs}{131}{}%
\contentsline {subsection}{\numberline {A.2.1}Sufficiency}{131}{}%
\contentsline {subsection}{\numberline {A.2.2}Lower Bound of Mutual Information for Sufficiency}{132}{}%
\contentsline {subsection}{\numberline {A.2.3}Conditional Mutual Information of Noise}{133}{}%
\contentsline {subsection}{\numberline {A.2.4}Factorization of Bottleneck Loss}{134}{}%
\contentsline {section}{\numberline {A.3}Main Theorems and Proofs}{135}{}%
\contentsline {subsection}{\numberline {A.3.1}Strict Label Blindness in the Minimal Sufficient Statistic}{135}{}%
\contentsline {subsection}{\numberline {A.3.2}Independence of Filtered Distributions}{140}{}%
\contentsline {subsection}{\numberline {A.3.3}Strict Label Blindness in Filtered Distributions - Guaranteed OOD Failure}{141}{}%
\contentsline {subsection}{\numberline {A.3.4}Unavoidable Risk of Overlapping Out of Distribution Data}{143}{}%
\contentsline {chapter}{\numberline {B}Theoretical Proofs for Domain Feature Collapse}{144}{}%
\contentsline {section}{\numberline {B.1}Properties of Mutual Information and Entropy}{144}{}%
\contentsline {section}{\numberline {B.2}Main Theorems and Proofs}{145}{}%
\contentsline {subsection}{\numberline {B.2.1}Lower Bound of Mutual Information for Sufficiency}{146}{}%
\contentsline {subsection}{\numberline {B.2.2}Factorization of Bottleneck Loss}{147}{}%
\contentsline {subsection}{\numberline {B.2.3}Conditional Mutual Information of Noise}{147}{}%
\contentsline {subsection}{\numberline {B.2.4}Domain Feature Collapse}{149}{}%
\contentsline {section}{\numberline {B.3}Theorems and Proofs of Previous Work}{153}{}%
\contentsline {subsection}{\numberline {B.3.1}Sufficiency}{153}{}%
\contentsline {section}{\numberline {B.4}Two Stage Domain Filter}{155}{}%
\contentsline {section}{\numberline {B.5}Detailed Experimental Setup}{156}{}%
\contentsline {subsection}{\numberline {B.5.1}Adjacent OOD Construction}{156}{}%
\contentsline {subsection}{\numberline {B.5.2}Cross Entropy ResNet50}{156}{}%
\contentsline {subsection}{\numberline {B.5.3}Cross Entropy DinoV2}{156}{}%
\contentsline {subsection}{\numberline {B.5.4}Supervised Contrastive Learning ResNet50}{157}{}%
\contentsline {section}{\numberline {B.6}Detailed Experimental Results}{157}{}%
\contentsline {subsection}{\numberline {B.6.1}OOD Method References}{157}{}%
\contentsline {subsection}{\numberline {B.6.2}Experimental Results Summary}{157}{}%
